{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VpYk4dHcJyxN"
   },
   "source": [
    "# Example script for Hackathon\n",
    "\n",
    "Within each cycle of active learning, you can:\n",
    "\n",
    "1. Collect training data (original training data + your query data).\n",
    "\n",
    "2. Train a prediction model to predict the DMS_score for each mutant (e.g., M0A).\n",
    "\n",
    "3. Use the trained model to predict the score for all mutant in the test set.\n",
    "\n",
    "4. Select query mutants for next round based on certain criteria. You may want to make sure you don't query the same mutant twice as you only have a limited chances of making queries in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "PDuz5mihLReY"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "import argparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h9WI5oTTKdIY"
   },
   "source": [
    "## 1. collect training data\n",
    "\n",
    "Upload `sequence.fasta`, `train.csv`, and `test.csv` to the current runtime:\n",
    "\n",
    "1. click the folder icon on the left\n",
    "\n",
    "2. click the upload icon and upload the files to the current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "Tj-TUAeZLEUz",
    "outputId": "e3107d56-5b84-47d7-d267-14251f9802f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLREKMRRRLESGDKWFSLEFFPPRTAEGAVNLISRFDRMAAGGPLYIDVTWHPAGDPGSDKETSSMMIASTAVNYCGLETILHMTCCRQRLEEITGHLHKAKQLGLKNIMALRGDPIGDQWEEEEGGFNYAVDLVKHIRSEFGDYFDICVAGYPKGHPEAGSFEADLKHLKEKVSAGADFIITQLFFEADTFFRFVKACTDMGITCPIVPGIFPIQGYHSLRQLVKLSKLEVPQEIKDVIEPIKDNDAAIRNYGIELAVSLCQELLASGLVPGLHFYTLNREMATTEVLKRLGMWTEDPRRPLPWALSAHPKRREEDVRPIFWASRPKSYIYRTQEWDEFPNGRWGNSSSPAFGELKDYYLFYLKSKSPKEELLKMWGEELTSEESVFEVFVLYLSGEPNRNGHKVTCLPWNDEPLAAETSLLKEELLRVNRQGILTINSQPNINGKPSSDPIVGWGPSGGYVFQKAYLEFFTSRETAEALLQVLKKYELRVNYHLVNVKGENITNAPELQPNAVTWGIFPGREIIQPTVVDPVSFMFWKDEAFALWIERWGKLYEEESPSRTIIQYIHDNYFLVNLVDNDFPLDNCLWQVVEDTLELLNRPTQNARETEAP'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('sequence.fasta', 'r') as f:\n",
    "  data = f.readlines()\n",
    "\n",
    "sequence_wt = data[1].strip()\n",
    "sequence_wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dewLzhLYMUSJ",
    "outputId": "8fe734ef-6df3-4b6a-81b5-1bae48619077"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "656"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequence_wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "N-tkTaqtK9AD"
   },
   "outputs": [],
   "source": [
    "def get_mutated_sequence(mut, sequence_wt):\n",
    "  wt, pos, mt = mut[0], int(mut[1:-1]), mut[-1]\n",
    "\n",
    "  sequence = deepcopy(sequence_wt)\n",
    "\n",
    "  return sequence[:pos]+mt+sequence[pos+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "bZH3YKNVyR-m",
    "outputId": "0d53c229-acd6-477b-fdd0-c5b2a5d7aaa2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mutant</th>\n",
       "      <th>DMS_score</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M0Y</td>\n",
       "      <td>0.2730</td>\n",
       "      <td>YVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M0W</td>\n",
       "      <td>0.2857</td>\n",
       "      <td>WVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M0V</td>\n",
       "      <td>0.2153</td>\n",
       "      <td>VVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M0T</td>\n",
       "      <td>0.3122</td>\n",
       "      <td>TVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M0S</td>\n",
       "      <td>0.2180</td>\n",
       "      <td>SVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>P347D</td>\n",
       "      <td>0.3876</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>P347C</td>\n",
       "      <td>0.1837</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>P347A</td>\n",
       "      <td>0.4611</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>P347M</td>\n",
       "      <td>0.2412</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>P347H</td>\n",
       "      <td>0.1512</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1140 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mutant  DMS_score                                           sequence\n",
       "0       M0Y     0.2730  YVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "1       M0W     0.2857  WVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "2       M0V     0.2153  VVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "3       M0T     0.3122  TVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "4       M0S     0.2180  SVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "...     ...        ...                                                ...\n",
       "1135  P347D     0.3876  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "1136  P347C     0.1837  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "1137  P347A     0.4611  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "1138  P347M     0.2412  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "1139  P347H     0.1512  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "\n",
       "[1140 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_train['sequence'] = df_train.mutant.apply(lambda x: get_mutated_sequence(x, sequence_wt))\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "tqfIASlMLQe4",
    "outputId": "bafadbef-a0a7-439f-9b6f-944b90ec7d2f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mutant</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V1D</td>\n",
       "      <td>MDNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V1Y</td>\n",
       "      <td>MYNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V1C</td>\n",
       "      <td>MCNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V1A</td>\n",
       "      <td>MANEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V1E</td>\n",
       "      <td>MENEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11319</th>\n",
       "      <td>P655S</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11320</th>\n",
       "      <td>P655T</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11321</th>\n",
       "      <td>P655V</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11322</th>\n",
       "      <td>P655A</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11323</th>\n",
       "      <td>P655W</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11324 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mutant                                           sequence\n",
       "0        V1D  MDNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "1        V1Y  MYNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "2        V1C  MCNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "3        V1A  MANEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "4        V1E  MENEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "...      ...                                                ...\n",
       "11319  P655S  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "11320  P655T  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "11321  P655V  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "11322  P655A  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "11323  P655W  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...\n",
       "\n",
       "[11324 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('test.csv')\n",
    "df_test['sequence'] = df_test.mutant.apply(lambda x: get_mutated_sequence(x, sequence_wt))\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "scJu5h_tuO_2"
   },
   "outputs": [],
   "source": [
    "# TODO: integrate the query data that you acquired each round into df_train\n",
    "import os\n",
    "\n",
    "if os.path.exists('queried_data.csv'):\n",
    "    #Gotta figure out which data to query.\n",
    "    df_query = pd.read_csv('queried_data.csv')\n",
    "    df_query['sequence'] = df_query.mutant.apply(lambda x: get_mutated_sequence(x, sequence_wt))\n",
    "    df_train = pd.concat([df_train, df_query]).reset_index(drop=True)\n",
    "    print(\"Integrated queried data; new training data shape:\", df_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2cty7BGBLdgp"
   },
   "source": [
    "## 2. Train a prediction model\n",
    "\n",
    "Here, we provided a linear regression model and used one-hot encoding to encode each variant. You would need to build your own model to achieve better performances.\n",
    "\n",
    "Hint: you can perform cross-validation on the training set to evaluate your predictor before making predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "wB0Mv-eQ2vah"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading ESM embeddings:   0%|          | 0/1140 [00:00<?, ?it/s]/var/folders/_y/bc436g6d71s9gjsdm9yd1c4c0000gt/T/ipykernel_9624/3499210022.py:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  emb = torch.load(emb_file)['mean_representations'][self.layer]\n",
      "Loading ESM embeddings: 100%|██████████| 1140/1140 [00:00<00:00, 5161.76it/s]\n",
      "Loading ESM embeddings: 100%|██████████| 11324/11324 [00:02<00:00, 5158.22it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm  # for progress display\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ProteinDatasetESM(Dataset):\n",
    "    def __init__(self, df, seq2name, emb_dir, istrain=True, layer=33):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame containing at least a 'sequence' column.\n",
    "            seq2name (dict): Mapping from sequence to a unique name corresponding to the embedding file.\n",
    "            emb_dir (str): Directory where the embedding files are stored.\n",
    "            istrain (bool): Whether the dataset contains target labels (DMS_score).\n",
    "            layer (int): Which layer's representation to use from the embedding file.\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.seq2name = seq2name\n",
    "        self.emb_dir = emb_dir\n",
    "        self.layer = layer\n",
    "        self.has_target = 'DMS_score' in df.columns\n",
    "        self.num_samples = len(self.df)\n",
    "\n",
    "        # If targets are available, store them\n",
    "        if self.has_target:\n",
    "            self.targets = self.df['DMS_score'].values.astype(np.float32)\n",
    "\n",
    "        # Pre-load embeddings for all sequences\n",
    "        self.embeddings = []\n",
    "        for seq in tqdm(self.df['sequence'], desc='Loading ESM embeddings'):\n",
    "            name = self.seq2name[seq]\n",
    "            emb_file = os.path.join(self.emb_dir, f'{name}.pt')\n",
    "            # Load the embedding file and extract the specified layer's representation\n",
    "            emb = torch.load(emb_file)['mean_representations'][self.layer]\n",
    "            self.embeddings.append(emb)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        emb = self.embeddings[idx]\n",
    "        if self.has_target:\n",
    "            label = torch.tensor(self.targets[idx], dtype=torch.float)\n",
    "            return emb, label\n",
    "        else:\n",
    "            return emb\n",
    "\n",
    "#ESM\n",
    "\n",
    "train_seq2name = {seq: f'seq_{i}' for i, seq in enumerate(df_train['sequence'])}\n",
    "test_seq2name  = {seq: f'seq_{i}' for i, seq in enumerate(df_test['sequence'])}\n",
    "\n",
    "train_dataset = ProteinDatasetESM(df_train, train_seq2name, emb_dir='./esm_embeddings_train', istrain=True)\n",
    "test_dataset  = ProteinDatasetESM(df_test, test_seq2name, emb_dir='./esm_embeddings_test', istrain=False)\n",
    "\n",
    "seed = 0\n",
    "val_ratio = 0.2\n",
    "indices = list(range(len(train_dataset)))\n",
    "split = int(np.floor(val_ratio * len(train_dataset)))\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(indices)\n",
    "train_idx, val_idx = indices[split:], indices[:split]\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "train_subset = Subset(train_dataset, train_idx)\n",
    "val_subset   = Subset(train_dataset, val_idx)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "val_loader   = DataLoader(val_subset, batch_size=32, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "Training model 1/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:28<00:00, 10.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model 2/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:29<00:00, 10.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model 3/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:28<00:00, 10.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model 4/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:29<00:00, 10.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model 5/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:29<00:00, 10.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0: Predicted fitness = 0.5249, Uncertainty (std) = 0.7561\n",
      "Sample 1: Predicted fitness = 0.5671, Uncertainty (std) = 0.7085\n",
      "Sample 2: Predicted fitness = 0.4722, Uncertainty (std) = 0.7541\n",
      "Sample 3: Predicted fitness = 0.6419, Uncertainty (std) = 0.7897\n",
      "Sample 4: Predicted fitness = 0.5355, Uncertainty (std) = 0.8575\n",
      "Sample 5: Predicted fitness = 0.4896, Uncertainty (std) = 0.7995\n",
      "Sample 6: Predicted fitness = 0.6162, Uncertainty (std) = 0.7605\n",
      "Sample 7: Predicted fitness = 0.3535, Uncertainty (std) = 0.7873\n",
      "Sample 8: Predicted fitness = 0.4370, Uncertainty (std) = 0.7634\n",
      "Sample 9: Predicted fitness = 0.6064, Uncertainty (std) = 0.7174\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming ESM_MLP is defined as follows:\n",
    "class ESM_MLP(nn.Module):\n",
    "    def __init__(self, input_dim=1280, hidden_dim=512, dropout_rate=0.3):\n",
    "        super(ESM_MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim // 2)\n",
    "        self.fc3 = nn.Linear(hidden_dim // 2, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x.squeeze(-1)\n",
    "\n",
    "# Hyperparameters\n",
    "ensemble_size = 5\n",
    "num_epochs = 300\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "weight_decay = 1e-4\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# List to hold our ensemble models.\n",
    "ensemble_models = []\n",
    "\n",
    "# Train each ensemble member.\n",
    "for i in range(ensemble_size):\n",
    "    print(f\"\\nTraining model {i+1}/{ensemble_size}...\")\n",
    "    \n",
    "    # Instantiate a new model.\n",
    "    model = ESM_MLP(input_dim=1280).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # Training loop.\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item() * x_batch.size(0)\n",
    "        epoch_loss /= len(train_loader.dataset)\n",
    "        # Uncomment the next line to print epoch loss for each model.\n",
    "        # print(f\"Model {i+1}, Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "    \n",
    "    ensemble_models.append(model)\n",
    "\n",
    "# Function to compute ensemble predictions and uncertainty.\n",
    "def ensemble_predict(models, dataloader):\n",
    "    all_preds = []\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for x_batch in dataloader:\n",
    "                x_batch = x_batch.to(device)\n",
    "                pred = model(x_batch)\n",
    "                preds.append(pred.cpu().numpy())\n",
    "        preds = np.concatenate(preds)\n",
    "        all_preds.append(preds)\n",
    "    all_preds = np.array(all_preds)  # Shape: (ensemble_size, num_samples)\n",
    "    mean_preds = np.mean(all_preds, axis=0)\n",
    "    std_preds = np.std(all_preds, axis=0)\n",
    "    return mean_preds, std_preds\n",
    "\n",
    "# Create a DataLoader for the test set.\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Get ensemble predictions and uncertainty estimates.\n",
    "mean_predictions, uncertainty = ensemble_predict(ensemble_models, test_loader)\n",
    "\n",
    "# For demonstration, print the first 10 mean predictions and uncertainties.\n",
    "for i in range(10):\n",
    "    print(f\"Sample {i}: Predicted fitness = {mean_predictions[i]:.4f}, Uncertainty (std) = {uncertainty[i]:.4f}\")\n",
    "\n",
    "# You can use these uncertainty estimates to choose which test points to query next.\n",
    "# For example, you might select points with high uncertainty or a combination of high predicted fitness and high uncertainty.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11324.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.725133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.057139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.493538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.688131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.725233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.761590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.023016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count  11324.000000\n",
       "mean       0.725133\n",
       "std        0.057139\n",
       "min        0.493538\n",
       "25%        0.688131\n",
       "50%        0.725233\n",
       "75%        0.761590\n",
       "max        1.023016"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_describe = pd.DataFrame(uncertainty)\n",
    "df_describe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11324,)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['DMS_score_predicted'] = mean_predictions\n",
    "df_test[['mutant', 'DMS_score_predicted']].to_csv('predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:45<00:00,  5.30s/it]\n"
     ]
    }
   ],
   "source": [
    "def mc_dropout_predictions(model, dataloader, T=20):\n",
    "    \"\"\"\n",
    "    Perform T stochastic forward passes (with dropout enabled) to estimate uncertainty.\n",
    "    Returns:\n",
    "        means: Mean predictions over T passes.\n",
    "        stds: Standard deviation (uncertainty) of predictions.\n",
    "    \"\"\"\n",
    "    model.train()  # keep dropout active\n",
    "    all_preds = []\n",
    "    for _ in tqdm(range(T)):\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for x_batch, l in dataloader:\n",
    "                x_batch = x_batch\n",
    "                pred = model(x_batch)\n",
    "                preds.append(pred.cpu().numpy())\n",
    "        all_preds.append(np.concatenate(preds))\n",
    "    all_preds = np.array(all_preds)\n",
    "    means = np.mean(all_preds, axis=0)\n",
    "    stds = np.std(all_preds, axis=0)\n",
    "    return means, stds\n",
    "\n",
    "means , stds = mc_dropout_predictions(model_cv, train_loader, T=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNX78OGrRZ46"
   },
   "source": [
    "## 3. Select query for next round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "SBXWtW8zQpxG",
    "outputId": "f166c12a-1287-474b-a290-df119d230f4e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df_test\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"mutant\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"A4C\",\n          \"T652K\",\n          \"R5C\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"MVNECRGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLREKMRRRLESGDKWFSLEFFPPRTAEGAVNLISRFDRMAAGGPLYIDVTWHPAGDPGSDKETSSMMIASTAVNYCGLETILHMTCCRQRLEEITGHLHKAKQLGLKNIMALRGDPIGDQWEEEEGGFNYAVDLVKHIRSEFGDYFDICVAGYPKGHPEAGSFEADLKHLKEKVSAGADFIITQLFFEADTFFRFVKACTDMGITCPIVPGIFPIQGYHSLRQLVKLSKLEVPQEIKDVIEPIKDNDAAIRNYGIELAVSLCQELLASGLVPGLHFYTLNREMATTEVLKRLGMWTEDPRRPLPWALSAHPKRREEDVRPIFWASRPKSYIYRTQEWDEFPNGRWGNSSSPAFGELKDYYLFYLKSKSPKEELLKMWGEELTSEESVFEVFVLYLSGEPNRNGHKVTCLPWNDEPLAAETSLLKEELLRVNRQGILTINSQPNINGKPSSDPIVGWGPSGGYVFQKAYLEFFTSRETAEALLQVLKKYELRVNYHLVNVKGENITNAPELQPNAVTWGIFPGREIIQPTVVDPVSFMFWKDEAFALWIERWGKLYEEESPSRTIIQYIHDNYFLVNLVDNDFPLDNCLWQVVEDTLELLNRPTQNARETEAP\",\n          \"MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLREKMRRRLESGDKWFSLEFFPPRTAEGAVNLISRFDRMAAGGPLYIDVTWHPAGDPGSDKETSSMMIASTAVNYCGLETILHMTCCRQRLEEITGHLHKAKQLGLKNIMALRGDPIGDQWEEEEGGFNYAVDLVKHIRSEFGDYFDICVAGYPKGHPEAGSFEADLKHLKEKVSAGADFIITQLFFEADTFFRFVKACTDMGITCPIVPGIFPIQGYHSLRQLVKLSKLEVPQEIKDVIEPIKDNDAAIRNYGIELAVSLCQELLASGLVPGLHFYTLNREMATTEVLKRLGMWTEDPRRPLPWALSAHPKRREEDVRPIFWASRPKSYIYRTQEWDEFPNGRWGNSSSPAFGELKDYYLFYLKSKSPKEELLKMWGEELTSEESVFEVFVLYLSGEPNRNGHKVTCLPWNDEPLAAETSLLKEELLRVNRQGILTINSQPNINGKPSSDPIVGWGPSGGYVFQKAYLEFFTSRETAEALLQVLKKYELRVNYHLVNVKGENITNAPELQPNAVTWGIFPGREIIQPTVVDPVSFMFWKDEAFALWIERWGKLYEEESPSRTIIQYIHDNYFLVNLVDNDFPLDNCLWQVVEDTLELLNRPTQNAREKEAP\",\n          \"MVNEACGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLREKMRRRLESGDKWFSLEFFPPRTAEGAVNLISRFDRMAAGGPLYIDVTWHPAGDPGSDKETSSMMIASTAVNYCGLETILHMTCCRQRLEEITGHLHKAKQLGLKNIMALRGDPIGDQWEEEEGGFNYAVDLVKHIRSEFGDYFDICVAGYPKGHPEAGSFEADLKHLKEKVSAGADFIITQLFFEADTFFRFVKACTDMGITCPIVPGIFPIQGYHSLRQLVKLSKLEVPQEIKDVIEPIKDNDAAIRNYGIELAVSLCQELLASGLVPGLHFYTLNREMATTEVLKRLGMWTEDPRRPLPWALSAHPKRREEDVRPIFWASRPKSYIYRTQEWDEFPNGRWGNSSSPAFGELKDYYLFYLKSKSPKEELLKMWGEELTSEESVFEVFVLYLSGEPNRNGHKVTCLPWNDEPLAAETSLLKEELLRVNRQGILTINSQPNINGKPSSDPIVGWGPSGGYVFQKAYLEFFTSRETAEALLQVLKKYELRVNYHLVNVKGENITNAPELQPNAVTWGIFPGREIIQPTVVDPVSFMFWKDEAFALWIERWGKLYEEESPSRTIIQYIHDNYFLVNLVDNDFPLDNCLWQVVEDTLELLNRPTQNARETEAP\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DMS_score_predicted\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          -0.04927763342857361\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-ef84b7de-7682-4d0f-ad6a-75046419d217\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mutant</th>\n",
       "      <th>sequence</th>\n",
       "      <th>DMS_score_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11323</th>\n",
       "      <td>P655W</td>\n",
       "      <td>MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "      <td>-0.049278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V1D</td>\n",
       "      <td>MDNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "      <td>-0.049278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V1Y</td>\n",
       "      <td>MYNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "      <td>-0.049278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V1C</td>\n",
       "      <td>MCNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "      <td>-0.049278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V1A</td>\n",
       "      <td>MANEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "      <td>-0.049278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>N7R</td>\n",
       "      <td>MVNEARGRSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "      <td>-0.049278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>N7Q</td>\n",
       "      <td>MVNEARGQSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "      <td>-0.049278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>N7P</td>\n",
       "      <td>MVNEARGPSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "      <td>-0.049278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>N7M</td>\n",
       "      <td>MVNEARGMSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "      <td>-0.049278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>N7Y</td>\n",
       "      <td>MVNEARGYSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...</td>\n",
       "      <td>-0.049278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef84b7de-7682-4d0f-ad6a-75046419d217')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-ef84b7de-7682-4d0f-ad6a-75046419d217 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-ef84b7de-7682-4d0f-ad6a-75046419d217');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-3968473c-124c-4499-8972-3e2bc252f54a\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3968473c-124c-4499-8972-3e2bc252f54a')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-3968473c-124c-4499-8972-3e2bc252f54a button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "      mutant                                           sequence  \\\n",
       "11323  P655W  MVNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...   \n",
       "0        V1D  MDNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...   \n",
       "1        V1Y  MYNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...   \n",
       "2        V1C  MCNEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...   \n",
       "3        V1A  MANEARGNSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...   \n",
       "...      ...                                                ...   \n",
       "119      N7R  MVNEARGRSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...   \n",
       "120      N7Q  MVNEARGQSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...   \n",
       "121      N7P  MVNEARGPSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...   \n",
       "122      N7M  MVNEARGMSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...   \n",
       "123      N7Y  MVNEARGYSSLNPCLEGSASSGSESSKDSSRCSTPGLDPERHERLR...   \n",
       "\n",
       "       DMS_score_predicted  \n",
       "11323            -0.049278  \n",
       "0                -0.049278  \n",
       "1                -0.049278  \n",
       "2                -0.049278  \n",
       "3                -0.049278  \n",
       "...                    ...  \n",
       "119              -0.049278  \n",
       "120              -0.049278  \n",
       "121              -0.049278  \n",
       "122              -0.049278  \n",
       "123              -0.049278  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.sort_values('DMS_score_predicted', ascending=False).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k46Og-FBiKyu"
   },
   "outputs": [],
   "source": [
    "# Example: randomly select 100 test variants to be queried.\n",
    "# Note: random selection may not be a good strategy\n",
    "# TODO: select query mutants for the next round based on your own criteria\n",
    "\n",
    "querys = df_test.sort_values('DMS_score_predicted', ascending=False).head(100)['mutant'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ltHYwv3Pi0lx"
   },
   "outputs": [],
   "source": [
    "with open('query.txt', 'w') as f:\n",
    "    for mutant in querys:\n",
    "        f.write(mutant + '\\n')\n",
    "\n",
    "print(\"Query file 'query.txt' created with the following mutants:\")\n",
    "print(querys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "poqVl4sD7HhL"
   },
   "source": [
    "#Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h0_bETxm5cqU",
    "outputId": "1160d50f-3a23-4ed3-9b30-23fb12afba57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fair-esm\n",
      "  Downloading fair_esm-2.0.0-py3-none-any.whl.metadata (37 kB)\n",
      "Downloading fair_esm-2.0.0-py3-none-any.whl (93 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/93.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: fair-esm\n",
      "Successfully installed fair-esm-2.0.0\n",
      "Collecting biopython\n",
      "  Downloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from biopython) (2.0.2)\n",
      "Downloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: biopython\n",
      "Successfully installed biopython-1.85\n"
     ]
    }
   ],
   "source": [
    "!pip install fair-esm\n",
    "!pip install biopython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347,
     "referenced_widgets": [
      "684f7165a33f4c198840b10c52cdb5b8",
      "08bacfb15137406a99d201956c6a4801",
      "ef1cbab3678246aeb039a81a61dd30b7",
      "9dfbda8f831646cbac7476ae07408c07",
      "f90be82a7a4d46cfbbc77789a29ffe80",
      "c7aa2a18a3d840f7bf2ad070e91d6374",
      "c68026db87f04303bec53ddf2bd815dc",
      "29444c4343ea4971ae93e4e188eedd53",
      "158c1cca1caf419d909ea1c501067438",
      "2352b59f964146e9915de8ac0313fe79",
      "ca76417a4e3849199dedeeee8da9be4b"
     ]
    },
    "id": "O3LPA4_Y5XQc",
    "outputId": "22b7d2cc-fd8b-465c-910b-c4be68c6e7cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 11324\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "684f7165a33f4c198840b10c52cdb5b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing batches:   0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-fe91e44115ad>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m# Example usage:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;31m# Assuming `df` is a DataFrame with a column 'sequence' (and optionally an 'id' column):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0mgen_emb_from_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sequence'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'esm_embeddings_test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-fe91e44115ad>\u001b[0m in \u001b[0;36mgen_emb_from_df\u001b[0;34m(df, sequence_col, id_col, out_dir, device)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mseq_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_representations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mtokens_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mseq_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0msave\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'mean_representations'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m33\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mseq_mean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{seq_name}.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import esm\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def gen_emb_from_df(df, sequence_col='sequence', id_col=None, out_dir='esm_embeddings', device='cuda:0'):\n",
    "    \"\"\"\n",
    "    Generate ESM-2 embeddings from sequences stored in a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing sequences.\n",
    "        sequence_col (str): Name of the column containing sequences.\n",
    "        id_col (str or None): Name of the column containing sequence IDs.\n",
    "                              If None, default IDs will be generated.\n",
    "        out_dir (str): Directory to save embedding files.\n",
    "        device (str): Device to use for inference.\n",
    "    \"\"\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    # Get sequence IDs: either from a specified column or generate default ones.\n",
    "    if id_col is None:\n",
    "        names = [f'seq_{i}' for i in range(len(df))]\n",
    "    else:\n",
    "        names = df[id_col].tolist()\n",
    "\n",
    "    sequences = df[sequence_col].tolist()\n",
    "    print(f'Number of sequences: {len(sequences)}')\n",
    "\n",
    "    data = [(name, seq) for name, seq in zip(names, sequences)]\n",
    "\n",
    "    # Load ESM-2 model (esm2_t33_650M_UR50D) and batch converter.\n",
    "    model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "    batch_converter = alphabet.get_batch_converter()\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()  # disables dropout for deterministic results\n",
    "\n",
    "    batch_size = 64  # Adjust if you run out of CUDA memory.\n",
    "    num_batches = int(np.ceil(len(data) / batch_size))\n",
    "\n",
    "    for i in tqdm(range(num_batches), desc=\"Processing batches\"):\n",
    "        batch = data[i * batch_size:(i + 1) * batch_size]\n",
    "        names_batch, seqs_batch = zip(*batch)\n",
    "        batch_labels, batch_strs, batch_tokens = batch_converter(batch)\n",
    "        batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
    "        batch_tokens = batch_tokens.to(device)\n",
    "\n",
    "        # Inference: extract per-residue representations from layer 33.\n",
    "        with torch.no_grad():\n",
    "            results = model(batch_tokens, repr_layers=[33], return_contacts=False)\n",
    "\n",
    "        # Get per-residue representations from the specified layer.\n",
    "        token_representations = results['representations'][33]\n",
    "\n",
    "        # Generate per-sequence representations via averaging.\n",
    "        for k, tokens_len in enumerate(batch_lens):\n",
    "            seq_name = names_batch[k]\n",
    "            seq_tokens = token_representations[k, :tokens_len]\n",
    "            seq_mean = seq_tokens.mean(0)\n",
    "            save = {'mean_representations': {33: seq_mean.cpu()}}\n",
    "            torch.save(save, os.path.join(out_dir, f'{seq_name}.pt'))\n",
    "\n",
    "# Assuming `df` is a DataFrame with a column 'sequence' (and optionally an 'id' column):\n",
    "gen_emb_from_df(df_test, sequence_col='sequence', out_dir='esm_embeddings_test')\n",
    "gen_emb_from_df(df_train, sequence_col='sequence', out_dir='esm_embeddings_train')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "spatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "08bacfb15137406a99d201956c6a4801": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c7aa2a18a3d840f7bf2ad070e91d6374",
      "placeholder": "​",
      "style": "IPY_MODEL_c68026db87f04303bec53ddf2bd815dc",
      "value": "Processing batches:  16%"
     }
    },
    "158c1cca1caf419d909ea1c501067438": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2352b59f964146e9915de8ac0313fe79": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "29444c4343ea4971ae93e4e188eedd53": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "684f7165a33f4c198840b10c52cdb5b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_08bacfb15137406a99d201956c6a4801",
       "IPY_MODEL_ef1cbab3678246aeb039a81a61dd30b7",
       "IPY_MODEL_9dfbda8f831646cbac7476ae07408c07"
      ],
      "layout": "IPY_MODEL_f90be82a7a4d46cfbbc77789a29ffe80"
     }
    },
    "9dfbda8f831646cbac7476ae07408c07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2352b59f964146e9915de8ac0313fe79",
      "placeholder": "​",
      "style": "IPY_MODEL_ca76417a4e3849199dedeeee8da9be4b",
      "value": " 29/177 [09:26&lt;47:20, 19.19s/it]"
     }
    },
    "c68026db87f04303bec53ddf2bd815dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c7aa2a18a3d840f7bf2ad070e91d6374": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca76417a4e3849199dedeeee8da9be4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ef1cbab3678246aeb039a81a61dd30b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_29444c4343ea4971ae93e4e188eedd53",
      "max": 177,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_158c1cca1caf419d909ea1c501067438",
      "value": 29
     }
    },
    "f90be82a7a4d46cfbbc77789a29ffe80": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
